{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (3876, 2)\n",
      "is_natural\n",
      "0.0    1938\n",
      "1.0    1938\n",
      "dtype: int64\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  18 out of  18 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'classification__strategy': 'stratified'}\n",
      "\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "[mean: 0.47730, std: 0.00813, params: {'classification__strategy': 'most_frequent'}, mean: 0.50722, std: 0.01376, params: {'classification__strategy': 'stratified'}, mean: 0.47730, std: 0.00813, params: {'classification__strategy': 'prior'}, mean: 0.48555, std: 0.03326, params: {'classification__strategy': 'uniform'}, mean: 0.50000, std: 0.02411, params: {'classification__strategy': 'constant', 'classification__constant': 0}, mean: 0.50000, std: 0.02411, params: {'classification__strategy': 'constant', 'classification__constant': 1}]\n",
      "\n",
      "Used scorer:\t make_scorer(accuracy_score)\n",
      "\n",
      "Best score:\t 0.507223942208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ДОМАШНЕЕ ЗАДАНИЕ\n",
    "\n",
    "Задача:\n",
    "\n",
    "- разработать классификатор, который умеет отделять естественные тексты от сгенерированных, \n",
    "  по точности он должен работать \"устойчиво лучше\" чем мой \"базовый\" -- для всех я буду у себя запускать одну\n",
    "  и ту же модель; оригинальный текст использовать, разумеется, нельзя;\n",
    "  \n",
    "- продемонстрировать, что вы умеете подбирать параметры с помощью GridSearch и оценивать качество (accuracy), \n",
    "  используя KFold;\n",
    "\n",
    "- всё должно быть оформлено в виде отчёта с кодом в айпайтон-ноутбуке; результаты должны воспроизводиться и \n",
    "  выглядеть убедительно.\n",
    "\n",
    "----\n",
    "\n",
    "* Код при необходимости лучше разносить на разные клетки.\n",
    "\n",
    "* Предварительный \"исследовательский\" анализ данных приветствуется, равно как и \n",
    "  придуманные самостоятельно фичи.\n",
    "\n",
    "* Все отличия от исходного ноутбука нужно прокомментировать -- что и зачем вы делаете.\n",
    "\n",
    "* В конце ноутбука должны быть итоги и ваши размышления о том, \n",
    "  ПОЧЕМУ при каких-то параметрах ваша модель не работала, а при \"победных\" сработала.\n",
    "\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# может зависеть от версии sklearn\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df = pd.read_csv(\"works/anya.txt.csv\")\n",
    "\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(df.groupby([\"is_natural\"]).size())\n",
    "\n",
    "\"\"\" Длина предложения -- хороший ли признак в нашем случае?\n",
    "\n",
    "df[\"sent_length\"] = df[\"txt\"].map(lambda x : len(x.split(\" \")))\n",
    "df[\"sent_length\"].hist().plot()\n",
    "\n",
    "print(df.groupby([\"sent_length\", \"is_natural\"]).size())\n",
    "\"\"\"\n",
    "\n",
    "# hint: разберитесь, что делает TfIdfVectorizer\n",
    "# hint: посмотрите, какие ещё бывают векторизаторы для текстов\n",
    "# hint: обязательно посмотрите, какие ещё у них бывают параметры\n",
    "vectorizer = TfidfVectorizer(min_df=2)\n",
    "\n",
    "# hint: можно надеяться не только на векторизатор, а сделать собственные фичи\n",
    "# например, длина предложения -- чем не фича?\n",
    "\n",
    "# hint: прочитайте в документации, что делает DummyClassifier\n",
    "# hint: вам стоит выбрать более осмысленную модель : )\n",
    "model = DummyClassifier(random_state=42)\n",
    "\n",
    "# цепочка действий, которые будут произведены над данными\n",
    "pipeline = Pipeline([\n",
    "        # Мы могли бы и не склеивать пайплайн, а построить фичи для всех данных и только потом запустить\n",
    "        # подбор гиперпараметров только для предсказывающей модели.\n",
    "        # ----------------------------------------------------------------------------------------------\n",
    "        # Но это было бы нечестно (то есть оценки были бы слишком оптимистичными),\n",
    "        # так как значение tf-idf зависит от всего датасета, и это значит, \n",
    "        # надо подгонять \"векторизатор\" только по обучающей выборке, потому что \n",
    "        # \"в реальной жизни\" \"тестовых данных\" нет.\n",
    "    ('vectorization',  vectorizer),\n",
    "    ('classification', model),\n",
    "])\n",
    "\n",
    "# число разбиений\n",
    "# ЭТО МЕНЯТЬ НЕ НУЖНО\n",
    "n_fold = 3\n",
    "\n",
    "# решётка параметров для всего пайплайна pipeline\n",
    "# значения параметров, которые будем перебирать, когда будем искать лучшую модель\n",
    "# classification__ -- это префикс, соответствующий model (см. pipeline)\n",
    "# соответственно, для параметров векторизатора надо будет использовать другой (см. pipeline выше)\n",
    "param_grid = [\n",
    "  {'classification__strategy': [\"most_frequent\", \"stratified\", \"prior\", \"uniform\"]},\n",
    "  {'classification__strategy': [\"constant\"], \"classification__constant\": [0, 1]},\n",
    " ]\n",
    "\n",
    "# ознакомьтесь с параметрами KFold\n",
    "cv = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "    \n",
    "X_text = df[\"txt\"]\n",
    "y = df[\"is_natural\"]\n",
    "\n",
    "# посмотрите, что означает каждый параметр, и подберите подходящий\n",
    "clf = GridSearchCV(estimator=pipeline, cv=cv, param_grid=param_grid, n_jobs=4, verbose=1, scoring=\"accuracy\")\n",
    "clf.fit(X_text, y) \n",
    "\n",
    "print(\"\\nBest parameters set found on development set:\\n\")\n",
    "print(clf.best_params_)\n",
    "print(\"\\n\\nGrid scores on development set:\\n\")\n",
    "means = clf.grid_scores_\n",
    "print(means)\n",
    "\n",
    "# best_model = clf.best_estimator_\n",
    "# print(\"\\nBest model:\\t\", best_model)\n",
    "\n",
    "scorer = clf.scorer_\n",
    "print(\"\\nUsed scorer:\\t\", scorer)\n",
    "\n",
    "# выберите модель, векторизатор, их параметры так, \n",
    "# чтобы эта оценка была выше высланной преподавателем\n",
    "print(\"\\nBest score:\\t\", clf.best_score_)\n",
    "\n",
    "# Запустите клетку несколько раз. Значительно ли меняется результат?\n",
    "# Подставьте другие random_state и проделайте то же самое. Значительно ли меняется результат?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
